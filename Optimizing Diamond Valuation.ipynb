{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5179749,"sourceType":"datasetVersion","datasetId":3011343}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# Load the dataset\nfile_path = '/kaggle/input/the-largest-diamond-dataset-currely-on-kaggle/diamonds.csv'\ndiamonds_df = pd.read_csv(file_path)\n\n# Display the first few rows of the dataset for an overview\ndiamonds_df.head()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-27T23:06:59.793229Z","iopub.execute_input":"2023-11-27T23:06:59.793583Z","iopub.status.idle":"2023-11-27T23:07:01.015924Z","shell.execute_reply.started":"2023-11-27T23:06:59.793552Z","shell.execute_reply":"2023-11-27T23:07:01.015056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diamonds_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:07:01.018427Z","iopub.execute_input":"2023-11-27T23:07:01.019116Z","iopub.status.idle":"2023-11-27T23:07:01.159069Z","shell.execute_reply.started":"2023-11-27T23:07:01.019081Z","shell.execute_reply":"2023-11-27T23:07:01.157737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initial Data Analysis: Descriptive statistics and distributions\n\n# Descriptive Statistics\ndescriptive_stats = diamonds_df.describe()\n\n# Distribution of Categorical Features\ncategorical_features = diamonds_df.select_dtypes(include=['object']).columns\ncategorical_distribution = diamonds_df[categorical_features].describe()\n\ndescriptive_stats, categorical_distribution\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:07:01.160671Z","iopub.execute_input":"2023-11-27T23:07:01.161066Z","iopub.status.idle":"2023-11-27T23:07:01.630259Z","shell.execute_reply.started":"2023-11-27T23:07:01.161033Z","shell.execute_reply":"2023-11-27T23:07:01.628972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Basic Introspection of the Dataset:\n\nCut:\n\nRepresents the diamond's shape and quality of the cut. Includes standard cuts and the 'Cushion Modified' cut.\n\nColor:\n\nGrades from D (colorless) to Z (yellowish). Color is a subtle feature but important in valuation.\n\nClarity:\n\nIndicates the presence of inclusions and blemishes. Clarity is a key factor in evaluating diamond quality.\n\nCarat Weight:\n\nRefers to the diamond's mass. Larger carat weight can significantly increase a diamond's value.\n\nCut Quality:\n\nBased on the GIA Cut Grading System. A crucial factor in determining a diamond's brilliance and value.\n\nLab:\n\nIndicates the certification lab (GIA, IGI, HRD). Certification authenticity affects value.\n\nPolish and Symmetry:\n\nReflects the finishing touches on the diamond, affecting its sparkle and overall appearance.\n\nEye-Clean:\n\nDescribes whether inclusions are visible to the naked eye. Affects the perceived quality of the diamond.\n\nCulet Size and Condition:\n\nPertains to the bottom point of the diamond. Ideal culets maximize light reflection; chipping affects value.\n\nFancy Color Attributes:\n\nConcerns colored diamonds, their hues, and intensities. Colored diamonds have gained popularity and value.\n\nFluorescence:\n\nRefers to how diamonds react to UV light. Affects appearance and sometimes value.\n\nDimensions and Proportions:\n\nIncludes depth percentage, table percentage, and absolute measurements. These factors influence a diamond's light reflection and overall aesthetics.\n\nGirdle Thickness:\n\nImpacts how a diamond is set and its overall profile. Varies from extremely thin to extremely thick.\n\nTotal Sales Price:\n\nThe final price in dollars. This is likely the target variable for predictive modeling.\n\nInitial Data Analysis\nLet's conduct an initial analysis to understand the distribution and basic statistics of these features. This analysis will provide insights into the characteristics of the dataset, which is essential before proceeding to anomaly detection.\n\nInitial Data Analysis Results:\n\n\nDescriptive Statistics of Numerical Features:\n\nCarat Weight: Ranges from 0.08 to 19.35, with a median of 0.50, indicating a wide variety of diamond sizes.\n\nDepth Percent: Varies greatly from 0 to 98.7, which might indicate potential outliers or data entry errors.\n\nTable Percent: Also shows a wide range from 0 to 94, suggesting the need for further investigation into potential anomalies.\n\nMeasurements (Length, Width, Depth): Have a broad range, reflecting the diversity in diamond sizes and shapes.\n\nTotal Sales Price: Ranges from 200 to over 1.44 million, indicating a diverse dataset in terms of value.\n\nDistribution of Categorical Features:\n\nCut: 11 unique types, with 'Round' being the most common.\n\nColor: 11 grades, 'E' being the most frequent.\n\nClarity: 11 categories, with 'SI1' as the most common.\n\nCut Quality: 6 levels, 'Excellent' being the top.\n\nLab: 3 main labs, with GIA being the predominant one.\n\nSymmetry and Polish: Various grades, mostly 'Excellent'.\n\nEye Clean: 5 grades, but 'unknown' is the most frequent.\n\nCulet Size and Condition: Various sizes and conditions, with 'None' and 'unknown' being the most common respectively.\n\nFancy Color Attributes: A wide range of colors and intensities, but 'unknown' dominates these columns.\n\nFluorescence: Different levels of intensity, with 'None' being the most common.\n\n\nObservations:\nThe dataset is rich with diverse characteristics of diamonds, reflecting real-world variability.\nSome columns have a significant number of 'unknown' entries, particularly in the fancy color and eye-clean categories.\nThe wide ranges in certain numerical features suggest the presence of potential outliers.\n\nNext Steps:\nProceeding with anomaly detection is advisable to identify and address outliers, especially in numerical columns like depth percent, table percent, and measurements.","metadata":{}},{"cell_type":"markdown","source":"Outlier Analysis","metadata":{}},{"cell_type":"markdown","source":"Data Skewness: The dataset is skewed with a mix of many small diamonds and a few large, expensive ones.\n\nMelee Diamonds: These are diamonds ≤ 0.2 carats, often used for their reflective properties rather than size. They make up a small portion of the dataset.\n\nMinimal Impact of Very Small Diamonds: Removing diamonds smaller than a certain threshold (e.g., ≤ 0.15 carats) only eliminates a small number of rows, indicating that they do not significantly skew the data.\n\nUpper-End Analysis: The presence of very large diamonds (e.g., 18 carats) might seem unusual, but they are valuable for analysis because:\n\nThe data collection is unlikely to be erroneous.\nIt's uncertain how these outliers will affect model results.\nSome models are more robust to outliers, and data transformation can mitigate outlier effects.","metadata":{}},{"cell_type":"markdown","source":"Outlier Analysis Approach:\n\nUnderstanding Skewness:\nWe'll look at the skewness of the numerical features, especially those related to size and price, to understand the distribution better.\n\nBoxplot Analysis:\nGenerate boxplots for key numerical features to visually inspect for outliers, especially at the upper end of the distributions.\n\nHandling Outliers:\nThe dataset is unlikely to have errors in collection, we should be cautious in outright removing outliers. Instead, we might consider data transformation methods if necessary. We'll also look on the smaller diamonds and the rationale for not removing the lower-end outliers.\n\nFocus on All Columns:\nWe'll conduct this analysis across all relevant numerical columns to ensure a comprehensive understanding of the dataset's characteristics.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n#skewness = diamonds_df.skew()\n\nnumeric_columns = diamonds_df.select_dtypes(include=['float64', 'int64']).columns\nnumeric_skewness = diamonds_df[numeric_columns].skew()\n\nnumeric_skewness\n\n# Boxplots for key numerical features\nplt.figure(figsize=(20, 10))\n\n# List of key numerical features for boxplots\nkey_features = ['carat_weight', 'depth_percent', 'table_percent', 'meas_length', 'meas_width', 'meas_depth', 'total_sales_price']\n\nfor i, feature in enumerate(key_features):\n    plt.subplot(2, 4, i+1)\n    sns.boxplot(y=diamonds_df[feature])\n    plt.title(f'Boxplot of {feature}')\n\nplt.tight_layout()\nplt.show()\n\nnumeric_skewness[key_features]\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:07:02.761994Z","iopub.execute_input":"2023-11-27T23:07:02.762560Z","iopub.status.idle":"2023-11-27T23:07:04.757853Z","shell.execute_reply.started":"2023-11-27T23:07:02.762528Z","shell.execute_reply":"2023-11-27T23:07:04.756579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Outlier Analysis Results:\n\n\nSkewness of Key Numerical Features:\n\n* Carat Weight: Highly positively skewed (Skewness = 6.04), indicating a concentration of smaller diamonds and a few larger ones.\n* Depth Percent: Negatively skewed (Skewness = -5.13). This suggests some irregularities, possibly due to data entry errors or unique diamond cuts.\n* Table Percent: Also negatively skewed (Skewness = -4.54), indicating a similar pattern of potential irregularities.\n* Measurements (Length, Width, Depth): All are positively skewed, especially depth (Skewness = 24.15), indicating a concentration of smaller-sized diamonds with a few larger ones.\n* Total Sales Price: Highly positively skewed (Skewness = 19.41), reflecting the presence of a few very high-priced diamonds among mostly lower-priced ones.\n\nBoxplot Observations:\n\nThe boxplots reveal a number of outliers, particularly on the higher end of the scale for carat weight and total sales price.\n\nDepth percent and table percent show a spread of data points that might not necessarily be outliers but could indicate a variety of diamond shapes and cuts.\n\nInterpretation and Next Steps:\n\nThe dataset's skewness corroborates the observation of a mixture of many small and a few large, expensive diamonds.\n\nGiven the skewness and the boxplot observations, it seems prudent to retain these outliers as they represent legitimate variations in diamond characteristics and prices, and are not due to data collection errors.\n\nTransforming the data, especially for features like carat weight and total sales price, may help in modeling these skewed distributions more effectively.","metadata":{}},{"cell_type":"markdown","source":"Since the data is \"well-curated\" and the outliers are likely representative of real-world scenarios (like large diamonds), preserving the original data distribution might be more valuable for understanding and predicting real-world outcomes.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Extracting categorical and numerical columns from the dataset\ncategorical_columns = [feature for feature in diamonds_df.columns if diamonds_df[feature].dtypes == 'O']\nnumerical_columns = [feature for feature in diamonds_df.columns if diamonds_df[feature].dtypes != 'O']\nnumerical_columns.remove('Unnamed: 0')  # Removing the 'Unnamed: 0' column as it's just an index\n\n# List of features for analysis\nfeatures = numerical_columns + categorical_columns\ntarget = ['total_sales_price']\n\n# EDA: Pairplot for numerical features with hue based on 'cut_quality'\nsns.pairplot(diamonds_df[numerical_columns + ['cut_quality']], hue=\"cut_quality\")\nplt.show()\n\n# EDA: Bar plots for categorical features against total sales price\nfor cat in categorical_columns:\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='total_sales_price', y=cat, data=diamonds_df)\n    plt.xticks(rotation=75)\n    plt.title(\"Total Sales Price vs \" + cat)\n    plt.show()\n\n# EDA: Scatter plots for numerical features against total sales price with hue based on 'cut_quality'\nfor num in numerical_columns:\n    if num != 'total_sales_price':  # Avoiding plotting the target against itself\n        sns.relplot(x='total_sales_price', y=num, hue='cut_quality', data=diamonds_df)\n        plt.xticks(rotation=75)\n        plt.title(\"Total Sales Price vs \" + num)\n        plt.show()\n\n# EDA: Distribution plots for numerical features\nfor num in numerical_columns:\n    sns.kdeplot(diamonds_df[num])\n    plt.xticks(rotation=75)\n    plt.title(\"Distribution of \" + num)\n    plt.show()\n\n# Distribution of the target variable\nsns.kdeplot(diamonds_df['total_sales_price'], gridsize=100)\nplt.title('Distribution of Total Sales Price')\nplt.show()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T19:45:26.927656Z","iopub.execute_input":"2023-11-27T19:45:26.927995Z","iopub.status.idle":"2023-11-27T19:59:22.436404Z","shell.execute_reply.started":"2023-11-27T19:45:26.927966Z","shell.execute_reply":"2023-11-27T19:59:22.435313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"EDA - Cut Analysis\nLet's start with an analysis of the 'cut' feature. We'll create a count plot to visualize the distribution of different diamond cuts and then calculate the percentage of each cut type in the dataset.\n\nI will proceed with the cut analysis first.","metadata":{"execution":{"iopub.status.busy":"2023-11-27T15:43:30.312829Z","iopub.execute_input":"2023-11-27T15:43:30.313198Z","iopub.status.idle":"2023-11-27T15:43:30.340158Z","shell.execute_reply.started":"2023-11-27T15:43:30.313168Z","shell.execute_reply":"2023-11-27T15:43:30.339017Z"}}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n# Count plot for the distribution of diamond cuts\nplt.figure(figsize=(12, 6))\nsns.set_palette(palette=\"ch:s=.25,rot=-.25\", n_colors=14)\nsns.countplot(x='cut', data=diamonds_df, order=diamonds_df['cut'].value_counts().index)\nplt.title('Distribution of Diamond Cuts')\nplt.xticks(rotation=45)\nplt.show()\n\n# Calculate the percentage of each cut type\ncut_counts = diamonds_df['cut'].value_counts()\ntotal_diamonds = len(diamonds_df)\ncut_percentages = (cut_counts / total_diamonds) * 100\n\ncut_percentages\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:07:14.760663Z","iopub.execute_input":"2023-11-27T23:07:14.761018Z","iopub.status.idle":"2023-11-27T23:07:15.116598Z","shell.execute_reply.started":"2023-11-27T23:07:14.760991Z","shell.execute_reply":"2023-11-27T23:07:15.115474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cut Analysis Results:\n\nDistribution of Diamond Cuts:\n\nRound Cut: The most prevalent, comprising 72.06% of all diamonds in the dataset.\nOval Cut: The second most common, accounting for 6.31%.\nOther cuts like Emerald, Pear, and Princess follow, each representing smaller percentages of the total.\n\nInsights:\nThe dominance of the round cut aligns with market trends, where round diamonds are often preferred for their brilliance and traditional appeal.\nThe diversity in cuts reflects a range of preferences and uses in the diamond market.","metadata":{}},{"cell_type":"markdown","source":"Color Analysis ","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Count plot for the distribution of diamond colors\nplt.figure(figsize=(12, 6))\nsns.set_palette(palette=\"light:#edf5dc\", n_colors=11)\ncolors_order = ['D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'fancy']\nsns.countplot(x='color', data=diamonds_df, order=colors_order)\nplt.title('Distribution of Diamond Colors')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:07:16.173473Z","iopub.execute_input":"2023-11-27T23:07:16.173874Z","iopub.status.idle":"2023-11-27T23:07:16.462696Z","shell.execute_reply.started":"2023-11-27T23:07:16.173847Z","shell.execute_reply":"2023-11-27T23:07:16.462049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The count plot illustrates the distribution of diamond colors in the dataset. The colors range from D (colorless) to M (yellowish) and include fancy colored diamonds.\n\nObservations:\nThe plot reveals the prevalence of certain color grades over others, but the specific counts and percentages are not shown in this visualization.\nThis distribution provides insights into the popularity and availability of different color grades in the diamond market.\nNext Step:\nWe can proceed with the analysis of the 'clarity' feature, which will involve examining the distribution of clarity grades among the diamonds in the dataset. ","metadata":{}},{"cell_type":"markdown","source":"Clarity Analysis ","metadata":{}},{"cell_type":"code","source":"# Count plot for the distribution of diamond clarity\nplt.figure(figsize=(12, 6))\nsns.set_palette(palette=\"ch:s=.55,rot=-.75\", n_colors=14)\nclarities_order = ['FL', 'IF', 'VVS1', 'VVS2', 'VS1', 'VS2', 'SI1', 'SI2', 'SI3', 'I1', 'I2', 'I3']\nsns.countplot(x='clarity', data=diamonds_df, order=clarities_order)\nplt.title('Distribution of Diamond Clarity')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:07:18.500755Z","iopub.execute_input":"2023-11-27T23:07:18.501448Z","iopub.status.idle":"2023-11-27T23:07:18.814910Z","shell.execute_reply.started":"2023-11-27T23:07:18.501388Z","shell.execute_reply":"2023-11-27T23:07:18.813443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The count plot presents the distribution of clarity grades among the diamonds in the dataset. The grades range from FL (Flawless) to I3 (Included), providing a comprehensive view of clarity variations.\n\nObservations:\nSimilar to the color analysis, this plot shows the prevalence of certain clarity grades over others, offering insights into the quality distribution of the diamonds in the market.","metadata":{}},{"cell_type":"markdown","source":"Carat Weight Analysis","metadata":{}},{"cell_type":"code","source":"# Scatter plot to show the relationship between carat weight and total sales price\nplt.figure(figsize=(15, 9))\nsns.scatterplot(data=diamonds_df, x=\"carat_weight\", y=\"total_sales_price\")\nplt.title('Carat Weight vs Total Sales Price')\nplt.show()\n\n# Investigating common carat sizes and price breakpoints\n# Identifying gaps around $1000 in total sales price\ngap_analysis = diamonds_df.loc[diamonds_df['total_sales_price'].between(500, 1700)]\nplt.figure(figsize=(15, 9))\nsns.countplot(data=gap_analysis, x='total_sales_price', color='green')\nplt.title('Distribution of Total Sales Price (Between $500 and $1700)')\nplt.xticks(rotation=90)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:07:21.131366Z","iopub.execute_input":"2023-11-27T23:07:21.131687Z","iopub.status.idle":"2023-11-27T23:07:26.188662Z","shell.execute_reply.started":"2023-11-27T23:07:21.131662Z","shell.execute_reply":"2023-11-27T23:07:26.187368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Carat Weight vs Total Sales Price:\nThe scatter plot illustrates the relationship between carat weight and total sales price.\nThere are several vertical lines in the plot, indicating common carat sizes. These may reflect psychological price points in the diamond market.\nThe plot also shows a general trend of increasing price with increasing carat weight, though with considerable variability.\nPrice Breakpoints Analysis:\nThe count plot for the total sales price (ranging from 500 to 1700) does not show any significant gaps or breakpoints around $1000. The values appear continuous over this range.\nThis continuity suggests that there is no distinct breakpoint in pricing within this specific range.","metadata":{}},{"cell_type":"code","source":"# Segmenting one-carat diamonds and examining their price ranges and attributes\none_carat_diamonds = diamonds_df.loc[diamonds_df['carat_weight'].between(0.9, 1.2)]\n\n# Analyzing one-carat diamonds within a specific price range (between $1800 and $12000)\none_carat_price_range = one_carat_diamonds.loc[one_carat_diamonds['total_sales_price'].between(1800, 12000)]\n\n# Boxen plots for different attributes of one-carat diamonds within the specified price range\n# Cut analysis\nplt.figure(figsize=(15, 6))\nsns.set_palette(palette=\"colorblind\")\nsns.boxenplot(data=one_carat_price_range, x=\"cut\", y=\"total_sales_price\", order=one_carat_price_range['cut'].value_counts().index)\nplt.title('One Carat Diamonds (Between $1800 and $12k) - Cut Analysis')\nplt.show()\n\n# Color analysis\nplt.figure(figsize=(15, 3))\nsns.set_palette(palette=\"light:#edf5dc\", n_colors=11)\ncolors = ['D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'fancy']\nsns.boxenplot(data=one_carat_price_range, x=\"color\", y=\"total_sales_price\", order=colors)\nplt.title('One Carat Diamonds (Between $1800 and $12k) - Color Analysis')\nplt.show()\n\n# Clarity analysis\nplt.figure(figsize=(15, 3))\nsns.set_palette(palette='Blues', n_colors=12)\nclarities = ['FL', 'IF', 'VVS1', 'VVS2', 'VS1', 'VS2', 'SI1', 'SI2', 'SI3', 'I1', 'I2', 'I3']\nsns.boxenplot(data=one_carat_price_range, x=\"clarity\", y=\"total_sales_price\", order=clarities)\nplt.title('One Carat Diamonds (Between $1800 and $12k) - Clarity Analysis')\nplt.show()\n\n# Cut quality analysis\nplt.figure(figsize=(15, 3))\nsns.set_palette(palette='Greens', n_colors=5)\ncut_qualities =['Excellent', 'Very Good', 'Good', 'Fair', 'Ideal']\nsns.boxenplot(data=one_carat_price_range, x=\"cut_quality\", y=\"total_sales_price\", order=cut_qualities)\nplt.title('One Carat Diamonds (Between $1800 and $12k) - Cut Quality Analysis')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:07:26.190705Z","iopub.execute_input":"2023-11-27T23:07:26.191073Z","iopub.status.idle":"2023-11-27T23:07:27.633344Z","shell.execute_reply.started":"2023-11-27T23:07:26.191045Z","shell.execute_reply":"2023-11-27T23:07:27.632077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Segment Analysis Results: One Carat Diamonds (Price Range 1800 to 12,000)\n\nCut Analysis:\nThe boxen plot for different cuts shows a variation in price distribution. Some cuts like Round, Princess, and Oval seem to have a wider price range.\n\nColor Analysis:\nThe color analysis indicates a trend in price variability across different color grades. Notably, D and E color diamonds have higher median prices.\n\nClarity Analysis:\nClarity grades show distinct price distributions. Higher clarity grades like FL, IF, VVS1, and VVS2 tend to have higher median prices.\n\nCut Quality Analysis:\nThere is a noticeable variation in price based on cut quality. Diamonds with 'Excellent' and 'Very Good' cut qualities show higher price ranges compared to others.\n\nInsights:\nThese analyses provide valuable insights into how cut, color, clarity, and cut quality influence the prices of one-carat diamonds within this specific price range.\n\nThe variability in prices based on these attributes highlights the complex interplay of factors that determine a diamond's value.","metadata":{}},{"cell_type":"markdown","source":"Given the extensive EDA we've already conducted on the 4Cs (Cut, Color, Clarity, and Carat Weight), we can now explore some of the other interesting aspects of the dataset. Here are a few ideas:\n\nLab Analysis:\nInvestigate the distribution and impact of different diamond grading labs (GIA, IGI, HRD) on prices.\n\nPolish and Symmetry:\nAnalyze how polish and symmetry ratings influence the total sales price.\n\nFancy Color Diamonds:\nExplore the distribution and price implications of fancy colored diamonds.\n\nFluorescence Analysis:\nExamine the impact of fluorescence on diamond prices.\n\nCulet Size and Condition:\nInvestigate how the culet size and condition affect the diamond's value.","metadata":{}},{"cell_type":"code","source":"# Lab Analysis: Distribution and impact on prices\nplt.figure(figsize=(12, 6))\nsns.boxenplot(x='lab', y='total_sales_price', data=diamonds_df)\nplt.title('Impact of Grading Lab on Total Sales Price')\nplt.show()\n\n# Polish and Symmetry Analysis\nplt.figure(figsize=(15, 6))\nplt.subplot(1, 2, 1)\nsns.boxenplot(x='polish', y='total_sales_price', data=diamonds_df)\nplt.title('Impact of Polish on Total Sales Price')\n\nplt.subplot(1, 2, 2)\nsns.boxenplot(x='symmetry', y='total_sales_price', data=diamonds_df)\nplt.title('Impact of Symmetry on Total Sales Price')\nplt.show()\n\n# Fancy Color Diamonds Analysis\nplt.figure(figsize=(12, 6))\nsns.boxenplot(x='fancy_color_dominant_color', y='total_sales_price', data=diamonds_df)\nplt.title('Impact of Fancy Color on Total Sales Price')\nplt.xticks(rotation=45)\nplt.show()\n\n# Fluorescence Analysis\nplt.figure(figsize=(12, 6))\nsns.boxenplot(x='fluor_intensity', y='total_sales_price', data=diamonds_df)\nplt.title('Impact of Fluorescence on Total Sales Price')\nplt.xticks(rotation=45)\nplt.show()\n\n# Culet Size and Condition Analysis\nplt.figure(figsize=(15, 6))\nplt.subplot(1, 2, 1)\nsns.boxenplot(x='culet_size', y='total_sales_price', data=diamonds_df)\nplt.title('Impact of Culet Size on Total Sales Price')\nplt.xticks(rotation=45)\n\nplt.subplot(1, 2, 2)\nsns.boxenplot(x='culet_condition', y='total_sales_price', data=diamonds_df)\nplt.title('Impact of Culet Condition on Total Sales Price')\nplt.xticks(rotation=45)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:07:27.634811Z","iopub.execute_input":"2023-11-27T23:07:27.635285Z","iopub.status.idle":"2023-11-27T23:07:29.965541Z","shell.execute_reply.started":"2023-11-27T23:07:27.635257Z","shell.execute_reply":"2023-11-27T23:07:29.963879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Lab Analysis:\nThe boxen plots show variation in total sales prices across different grading labs (GIA, IGI, HRD). Some labs appear to have a higher median price, possibly indicating a perceived higher quality or market preference.\n2. Polish and Symmetry Analysis:\nPolish: Different polish grades show varied impacts on total sales price, with some grades associated with higher prices.\nSymmetry: Similar to polish, symmetry grades also influence the price, with certain grades fetching higher prices.\n3. Fancy Color Diamonds Analysis:\nFancy colored diamonds show a diverse range of prices. Some colors appear to command higher prices, reflecting rarity or market demand for specific colors.\n4. Fluorescence Analysis:\nThe impact of fluorescence intensity on diamond prices is illustrated. There's noticeable variability in price based on fluorescence characteristics.\n5. Culet Size and Condition Analysis:\nCulet Size: Different culet sizes impact the price, with some sizes being associated with higher or lower prices.\nCulet Condition: The condition of the culet also influences the price, indicating the importance of this feature in overall diamond valuation.\nInsights:\nThese analyses reveal the multifaceted nature of diamond valuation, where factors beyond the 4Cs also play significant roles.\nUnderstanding these additional attributes can provide a more rounded view of what influences diamond prices.","metadata":{}},{"cell_type":"markdown","source":"Applying min-max scaling for the numerical features","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nnumeric_features = diamonds_df.select_dtypes(include=['float64', 'int64']).columns\nnumeric_features = numeric_features.drop('Unnamed: 0')  # Exclude ID column\n\n# min_max_scaler = MinMaxScaler()\n# diamonds_df_scaled = diamonds_df.copy()\n\n# numeric_features_to_scale = [feature for feature in numeric_features if feature != 'total_sales_price']\n\n# # Applying Min-Max Scaling\n# diamonds_df_scaled[numeric_features_to_scale] = min_max_scaler.fit_transform(diamonds_df[numeric_features_to_scale])\n\n# # Displaying the first few rows of the scaled dataset (excluding total_sales_price)\n# diamonds_df_scaled[numeric_features_to_scale].head()\n\nfrom sklearn.preprocessing import RobustScaler\n\n# Initialize the Robust Scaler\nrobust_scaler = RobustScaler()\n\n# Select numeric features for scaling, excluding the target variable\nnumeric_features_to_scale = [feature for feature in numeric_features if feature != 'total_sales_price']\n\n# Apply Robust Scaler to the numeric features\ndiamonds_df_robust_scaled = diamonds_df.copy()\ndiamonds_df_robust_scaled[numeric_features_to_scale] = robust_scaler.fit_transform(diamonds_df[numeric_features_to_scale])\n\n# Check the first few rows of the scaled data\nprint(diamonds_df_robust_scaled[numeric_features_to_scale].head())\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:07:49.836125Z","iopub.execute_input":"2023-11-27T23:07:49.837072Z","iopub.status.idle":"2023-11-27T23:07:49.935624Z","shell.execute_reply.started":"2023-11-27T23:07:49.837027Z","shell.execute_reply":"2023-11-27T23:07:49.934598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Applying One Hot Encoding for Categorical Features","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\n# Identifying categorical columns\ncategorical_columns = diamonds_df.select_dtypes(include=['object']).columns\n\n# Applying One-Hot Encoding to categorical variables\none_hot_encoder = OneHotEncoder(sparse=False, drop='first')\nencoded_categorical_data = one_hot_encoder.fit_transform(diamonds_df[categorical_columns])\n\n# Creating a DataFrame for encoded categorical features\nencoded_categorical_df = pd.DataFrame(encoded_categorical_data, columns=one_hot_encoder.get_feature_names_out(categorical_columns))\n\n# Concatenating the encoded categorical features with the scaled numeric features\ndiamonds_df_preprocessed = pd.concat([diamonds_df_robust_scaled.drop(categorical_columns, axis=1), encoded_categorical_df], axis=1)\n\n# Displaying the first few rows of the preprocessed dataset\ndiamonds_df_preprocessed.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:07:52.057316Z","iopub.execute_input":"2023-11-27T23:07:52.057695Z","iopub.status.idle":"2023-11-27T23:07:53.549097Z","shell.execute_reply.started":"2023-11-27T23:07:52.057665Z","shell.execute_reply":"2023-11-27T23:07:53.547372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Splitting and making a baseline Linear Regressor Model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Define the features and target variable\nX = diamonds_df_preprocessed.drop(['total_sales_price', 'Unnamed: 0'], axis=1)  # Exclude target and ID column\ny = diamonds_df_preprocessed['total_sales_price']\n\n# Split the dataset into training (80%) and testing (20%) sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:07:55.510777Z","iopub.execute_input":"2023-11-27T23:07:55.511186Z","iopub.status.idle":"2023-11-27T23:07:55.760629Z","shell.execute_reply.started":"2023-11-27T23:07:55.511139Z","shell.execute_reply":"2023-11-27T23:07:55.759409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Initialize the Linear Regression model\nlinear_model = LinearRegression()\n\n# Fit the model on the training data\nlinear_model.fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:07:56.938918Z","iopub.execute_input":"2023-11-27T23:07:56.939319Z","iopub.status.idle":"2023-11-27T23:07:58.033914Z","shell.execute_reply.started":"2023-11-27T23:07:56.939291Z","shell.execute_reply":"2023-11-27T23:07:58.033205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict on the test set\ny_pred = linear_model.predict(X_test)\n\n# Calculate RMSE and R^2\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\n\nprint(\"RMSE:\", rmse)\nprint(\"R^2:\", r2)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:07:59.167125Z","iopub.execute_input":"2023-11-27T23:07:59.167503Z","iopub.status.idle":"2023-11-27T23:07:59.193663Z","shell.execute_reply.started":"2023-11-27T23:07:59.167476Z","shell.execute_reply":"2023-11-27T23:07:59.192882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\n# Initialize the Random Forest Regressor\nrandom_forest_model = RandomForestRegressor(n_estimators=100, random_state=42)\n\n# Fit the model on the training data\nrandom_forest_model.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred_rf = random_forest_model.predict(X_test)\n\n# Calculate RMSE and R^2 for Random Forest\nrmse_rf = mean_squared_error(y_test, y_pred_rf, squared=False)\nr2_rf = r2_score(y_test, y_pred_rf)\n\nprint(\"Random Forest RMSE:\", rmse_rf)\nprint(\"Random Forest R^2:\", r2_rf)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:08:00.778920Z","iopub.execute_input":"2023-11-27T23:08:00.779293Z","iopub.status.idle":"2023-11-27T23:13:01.940106Z","shell.execute_reply.started":"2023-11-27T23:08:00.779266Z","shell.execute_reply":"2023-11-27T23:13:01.938571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n\n# Initialize the Gradient Boosting Regressor\ngradient_boosting_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n\n# Fit the model on the training data\ngradient_boosting_model.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred_gb = gradient_boosting_model.predict(X_test)\n\n# Calculate RMSE and R^2 for Gradient Boosting\nrmse_gb = mean_squared_error(y_test, y_pred_gb, squared=False)\nr2_gb = r2_score(y_test, y_pred_gb)\n\nprint(\"Gradient Boosting RMSE:\", rmse_gb)\nprint(\"Gradient Boosting R^2:\", r2_gb)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:13:01.941757Z","iopub.execute_input":"2023-11-27T23:13:01.942077Z","iopub.status.idle":"2023-11-27T23:13:54.239980Z","shell.execute_reply.started":"2023-11-27T23:13:01.942042Z","shell.execute_reply":"2023-11-27T23:13:54.238062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\n\n# Initialize the XGBoost Regressor\nxgb_model = xgb.XGBRegressor(objective ='reg:squarederror', \n                             colsample_bytree = 0.3, \n                             learning_rate = 0.1,\n                             max_depth = 5, \n                             alpha = 10, \n                             n_estimators = 100)\n\n# Fit the model on the training data\nxgb_model.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred_xgb = xgb_model.predict(X_test)\n\n# Calculate RMSE and R^2 for XGBoost\nrmse_xgb = mean_squared_error(y_test, y_pred_xgb, squared=False)\nr2_xgb = r2_score(y_test, y_pred_xgb)\n\nprint(\"XGBoost RMSE:\", rmse_xgb)\nprint(\"XGBoost R^2:\", r2_xgb)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:13:54.241666Z","iopub.execute_input":"2023-11-27T23:13:54.241993Z","iopub.status.idle":"2023-11-27T23:13:59.300272Z","shell.execute_reply.started":"2023-11-27T23:13:54.241965Z","shell.execute_reply":"2023-11-27T23:13:59.299496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import SGDRegressor, Lasso, Ridge\nfrom sklearn.svm import SVR\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split, learning_curve, RandomizedSearchCV\nfrom sklearn.metrics import r2_score,make_scorer,mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:13:59.302390Z","iopub.execute_input":"2023-11-27T23:13:59.302710Z","iopub.status.idle":"2023-11-27T23:13:59.535872Z","shell.execute_reply.started":"2023-11-27T23:13:59.302681Z","shell.execute_reply":"2023-11-27T23:13:59.534795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = [KNeighborsRegressor(), SGDRegressor(), Lasso(), Ridge(), CatBoostRegressor(), XGBRegressor()]\nfor model in models:\n    model.fit(X_train, y_train)\n    ypred = model.predict(X_test)\n    score = r2_score(y_test, ypred)\n    print(\"model: {}  score {}\".format(model, score))","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:13:59.536999Z","iopub.execute_input":"2023-11-27T23:13:59.537309Z","iopub.status.idle":"2023-11-27T23:17:25.713133Z","shell.execute_reply.started":"2023-11-27T23:13:59.537284Z","shell.execute_reply":"2023-11-27T23:17:25.712431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom catboost import CatBoostRegressor\n\n# Define the parameter grid\nparam_grid = {\n    'depth': [4, 6, 8],\n    'learning_rate': [0.01, 0.05, 0.1],\n    'iterations': [30, 50, 100],\n    'l2_leaf_reg': [1, 3, 5]\n}\n\n# Initialize the CatBoost Regressor\ncatboost_model = CatBoostRegressor()\n\n# Initialize the Grid Search\ngrid_search = GridSearchCV(estimator=catboost_model, param_grid=param_grid, \n                           cv=3, n_jobs=-1, verbose=2, scoring='r2')\n\n# Fit the grid search to the data\ngrid_search.fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:18:51.094761Z","iopub.execute_input":"2023-11-27T23:18:51.095125Z","iopub.status.idle":"2023-11-27T23:23:08.221984Z","shell.execute_reply.started":"2023-11-27T23:18:51.095096Z","shell.execute_reply":"2023-11-27T23:23:08.221123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Best parameters\nbest_params = grid_search.best_params_  # Or random_search.best_params_\nprint(\"Best parameters:\", best_params)\n\n# Best model\nbest_model = grid_search.best_estimator_  # Or random_search.best_estimator_\n\n# Evaluate the best model\ny_pred = best_model.predict(X_test)\nr2 = r2_score(y_test, y_pred)\nprint(\"Best Model R^2:\", r2)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T23:23:08.223444Z","iopub.execute_input":"2023-11-27T23:23:08.224123Z","iopub.status.idle":"2023-11-27T23:23:08.251571Z","shell.execute_reply.started":"2023-11-27T23:23:08.224093Z","shell.execute_reply":"2023-11-27T23:23:08.250378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}